{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss, precision_score, accuracy_score, recall_score, f1_score\n",
    "from vaccine.model import DenseNet, Model\n",
    "import torch \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "data_dir = './DATA/'\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_protein_id</th>\n",
       "      <th>protein_seq</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>peptide_seq</th>\n",
       "      <th>chou_fasman</th>\n",
       "      <th>emini</th>\n",
       "      <th>kolaskar_tongaonkar</th>\n",
       "      <th>parker</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>stability</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2T3T0</td>\n",
       "      <td>MDVLYSLSKTLKDARDKIVEGTLYSNVSDLIQQFNQMIITMNGNEF...</td>\n",
       "      <td>161</td>\n",
       "      <td>165</td>\n",
       "      <td>SASFT</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.703</td>\n",
       "      <td>1.018</td>\n",
       "      <td>2.22</td>\n",
       "      <td>5.810364</td>\n",
       "      <td>0.103275</td>\n",
       "      <td>-0.143829</td>\n",
       "      <td>40.273300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F0V2I4</td>\n",
       "      <td>MTIHKVAINGFGRIGRLLFRNLLSSQGVQVVAVNDVVDIKVLTHLL...</td>\n",
       "      <td>251</td>\n",
       "      <td>255</td>\n",
       "      <td>LCLKI</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.199</td>\n",
       "      <td>-3.86</td>\n",
       "      <td>6.210876</td>\n",
       "      <td>0.065476</td>\n",
       "      <td>-0.036905</td>\n",
       "      <td>24.998512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O75508</td>\n",
       "      <td>MVATCLQVVGFVTSFVGWIGVIVTTSTNDWVVTCGYTIPTCRKLDE...</td>\n",
       "      <td>145</td>\n",
       "      <td>149</td>\n",
       "      <td>AHRET</td>\n",
       "      <td>0.852</td>\n",
       "      <td>3.427</td>\n",
       "      <td>0.960</td>\n",
       "      <td>4.28</td>\n",
       "      <td>8.223938</td>\n",
       "      <td>0.091787</td>\n",
       "      <td>0.879227</td>\n",
       "      <td>27.863333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O84462</td>\n",
       "      <td>MTNSISGYQPTVTTSTSSTTSASGASGSLGASSVSTTANATVTQTA...</td>\n",
       "      <td>152</td>\n",
       "      <td>156</td>\n",
       "      <td>SNYDD</td>\n",
       "      <td>1.410</td>\n",
       "      <td>2.548</td>\n",
       "      <td>0.936</td>\n",
       "      <td>6.32</td>\n",
       "      <td>4.237976</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>-0.521393</td>\n",
       "      <td>30.765373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P00918</td>\n",
       "      <td>MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...</td>\n",
       "      <td>85</td>\n",
       "      <td>89</td>\n",
       "      <td>DGTYR</td>\n",
       "      <td>1.214</td>\n",
       "      <td>1.908</td>\n",
       "      <td>0.937</td>\n",
       "      <td>4.64</td>\n",
       "      <td>6.867493</td>\n",
       "      <td>0.103846</td>\n",
       "      <td>-0.578846</td>\n",
       "      <td>21.684615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_protein_id                                        protein_seq  \\\n",
       "0            A2T3T0  MDVLYSLSKTLKDARDKIVEGTLYSNVSDLIQQFNQMIITMNGNEF...   \n",
       "1            F0V2I4  MTIHKVAINGFGRIGRLLFRNLLSSQGVQVVAVNDVVDIKVLTHLL...   \n",
       "2            O75508  MVATCLQVVGFVTSFVGWIGVIVTTSTNDWVVTCGYTIPTCRKLDE...   \n",
       "3            O84462  MTNSISGYQPTVTTSTSSTTSASGASGSLGASSVSTTANATVTQTA...   \n",
       "4            P00918  MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...   \n",
       "\n",
       "   start_position  end_position peptide_seq  chou_fasman  emini  \\\n",
       "0             161           165       SASFT        1.016  0.703   \n",
       "1             251           255       LCLKI        0.770  0.179   \n",
       "2             145           149       AHRET        0.852  3.427   \n",
       "3             152           156       SNYDD        1.410  2.548   \n",
       "4              85            89       DGTYR        1.214  1.908   \n",
       "\n",
       "   kolaskar_tongaonkar  parker  isoelectric_point  aromaticity  \\\n",
       "0                1.018    2.22           5.810364     0.103275   \n",
       "1                1.199   -3.86           6.210876     0.065476   \n",
       "2                0.960    4.28           8.223938     0.091787   \n",
       "3                0.936    6.32           4.237976     0.044776   \n",
       "4                0.937    4.64           6.867493     0.103846   \n",
       "\n",
       "   hydrophobicity  stability  target  \n",
       "0       -0.143829  40.273300       1  \n",
       "1       -0.036905  24.998512       1  \n",
       "2        0.879227  27.863333       1  \n",
       "3       -0.521393  30.765373       1  \n",
       "4       -0.578846  21.684615       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bcell = pd.read_csv(data_dir+'input_bcell.csv')\n",
    "df_sars = pd.read_csv(data_dir+'input_sars.csv')\n",
    "df = pd.concat([df_bcell, df_sars], ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start_position', 'end_position', 'chou_fasman', 'emini', 'kolaskar_tongaonkar', 'parker', 'isoelectric_point', 'aromaticity', 'hydrophobicity', 'stability']\n"
     ]
    }
   ],
   "source": [
    "# feature columns\n",
    "feature_cols = [col for col in df.columns if col not in ['parent_protein_id', 'protein_seq', 'peptide_seq', 'target']]\n",
    "print(feature_cols)\n",
    "\n",
    "# split df into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[feature_cols], df.target, test_size=0.2, random_state=SEED)\n",
    "y_train = y_train.to_frame()\n",
    "y_test = y_test.to_frame()\n",
    "\n",
    "# normalization\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), index=X_train.index, columns=feature_cols)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11925, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling: NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/40] : train loss 0.712626, train metric 0.712626, val loss 0.710908, val metric 0.710908\n",
      "Epoch [4/40] : train loss 0.692080, train metric 0.692080, val loss 0.677051, val metric 0.677051\n",
      "Epoch [6/40] : train loss 0.631465, train metric 0.631465, val loss 0.663769, val metric 0.663769\n",
      "Epoch [8/40] : train loss 0.650723, train metric 0.650723, val loss 0.649774, val metric 0.649774\n",
      "Epoch [10/40] : train loss 0.632836, train metric 0.632836, val loss 0.637724, val metric 0.637724\n",
      "Epoch [12/40] : train loss 0.582108, train metric 0.582108, val loss 0.637094, val metric 0.637094\n",
      "Epoch [14/40] : train loss 0.582163, train metric 0.582163, val loss 0.628613, val metric 0.628613\n",
      "Epoch [16/40] : train loss 0.548272, train metric 0.548272, val loss 0.627860, val metric 0.627860\n",
      "Epoch [18/40] : train loss 0.576592, train metric 0.576592, val loss 0.620631, val metric 0.620631\n",
      "Epoch [20/40] : train loss 0.541382, train metric 0.541382, val loss 0.628303, val metric 0.628303\n",
      "Epoch [22/40] : train loss 0.488553, train metric 0.488553, val loss 0.630675, val metric 0.630675\n",
      "Epoch    21: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [24/40] : train loss 0.512750, train metric 0.512750, val loss 0.627684, val metric 0.627684\n",
      "Epoch [26/40] : train loss 0.450390, train metric 0.450390, val loss 0.626429, val metric 0.626429\n",
      "Epoch    26: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [28/40] : train loss 0.525098, train metric 0.525098, val loss 0.613382, val metric 0.613382\n",
      "Epoch [30/40] : train loss 0.553032, train metric 0.553032, val loss 0.618063, val metric 0.618063\n",
      "Epoch [32/40] : train loss 0.484228, train metric 0.484228, val loss 0.619145, val metric 0.619145\n",
      "Epoch    31: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch [34/40] : train loss 0.417873, train metric 0.417873, val loss 0.607272, val metric 0.607272\n",
      "Epoch [36/40] : train loss 0.444839, train metric 0.444839, val loss 0.612850, val metric 0.612850\n",
      "Epoch [38/40] : train loss 0.419138, train metric 0.419138, val loss 0.619199, val metric 0.619199\n",
      "Epoch    37: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch [40/40] : train loss 0.445087, train metric 0.445087, val loss 0.615671, val metric 0.615671\n",
      "Epoch [2/40] : train loss 0.743683, train metric 0.743683, val loss 0.701820, val metric 0.701820\n",
      "Epoch [4/40] : train loss 0.675828, train metric 0.675828, val loss 0.679268, val metric 0.679268\n",
      "Epoch [6/40] : train loss 0.684232, train metric 0.684232, val loss 0.665899, val metric 0.665899\n",
      "Epoch [8/40] : train loss 0.684106, train metric 0.684106, val loss 0.656370, val metric 0.656370\n",
      "Epoch [10/40] : train loss 0.626680, train metric 0.626680, val loss 0.643779, val metric 0.643779\n",
      "Epoch [12/40] : train loss 0.623395, train metric 0.623395, val loss 0.643105, val metric 0.643105\n",
      "Epoch [14/40] : train loss 0.591367, train metric 0.591367, val loss 0.636032, val metric 0.636032\n",
      "Epoch [16/40] : train loss 0.602315, train metric 0.602315, val loss 0.639431, val metric 0.639431\n",
      "Epoch [18/40] : train loss 0.630171, train metric 0.630171, val loss 0.627645, val metric 0.627645\n",
      "Epoch [20/40] : train loss 0.606061, train metric 0.606061, val loss 0.638836, val metric 0.638836\n",
      "Epoch [22/40] : train loss 0.546315, train metric 0.546315, val loss 0.625092, val metric 0.625092\n",
      "Epoch [24/40] : train loss 0.537044, train metric 0.537044, val loss 0.631311, val metric 0.631311\n",
      "Epoch [26/40] : train loss 0.479553, train metric 0.479553, val loss 0.630617, val metric 0.630617\n",
      "Epoch    25: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [28/40] : train loss 0.518007, train metric 0.518007, val loss 0.634613, val metric 0.634613\n",
      "Epoch [30/40] : train loss 0.492295, train metric 0.492295, val loss 0.631880, val metric 0.631880\n",
      "Epoch    30: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [32/40] : train loss 0.485554, train metric 0.485554, val loss 0.618271, val metric 0.618271\n",
      "Epoch [34/40] : train loss 0.441142, train metric 0.441142, val loss 0.619844, val metric 0.619844\n",
      "Epoch [36/40] : train loss 0.448180, train metric 0.448180, val loss 0.625166, val metric 0.625166\n",
      "Epoch    35: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch [38/40] : train loss 0.406247, train metric 0.406247, val loss 0.618756, val metric 0.618756\n",
      "Epoch [40/40] : train loss 0.444379, train metric 0.444379, val loss 0.619120, val metric 0.619120\n",
      "Epoch [2/40] : train loss 0.784052, train metric 0.784052, val loss 0.710169, val metric 0.710169\n",
      "Epoch [4/40] : train loss 0.711216, train metric 0.711216, val loss 0.685942, val metric 0.685942\n",
      "Epoch [6/40] : train loss 0.689947, train metric 0.689947, val loss 0.667194, val metric 0.667194\n",
      "Epoch [8/40] : train loss 0.682560, train metric 0.682560, val loss 0.662428, val metric 0.662428\n",
      "Epoch [10/40] : train loss 0.658565, train metric 0.658565, val loss 0.651286, val metric 0.651286\n",
      "Epoch [12/40] : train loss 0.619711, train metric 0.619711, val loss 0.643164, val metric 0.643164\n",
      "Epoch [14/40] : train loss 0.597873, train metric 0.597873, val loss 0.645285, val metric 0.645285\n",
      "Epoch [16/40] : train loss 0.608981, train metric 0.608981, val loss 0.643450, val metric 0.643450\n",
      "Epoch    16: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [18/40] : train loss 0.593804, train metric 0.593804, val loss 0.624587, val metric 0.624587\n",
      "Epoch [20/40] : train loss 0.560564, train metric 0.560564, val loss 0.626766, val metric 0.626766\n",
      "Epoch [22/40] : train loss 0.586584, train metric 0.586584, val loss 0.625190, val metric 0.625190\n",
      "Epoch    21: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [24/40] : train loss 0.479651, train metric 0.479651, val loss 0.627954, val metric 0.627954\n",
      "Epoch [26/40] : train loss 0.527633, train metric 0.527633, val loss 0.632988, val metric 0.632988\n",
      "Epoch    25: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch [28/40] : train loss 0.540952, train metric 0.540952, val loss 0.629853, val metric 0.629853\n",
      "Early stopping\n",
      "Epoch [2/40] : train loss 0.828466, train metric 0.828466, val loss 0.686270, val metric 0.686270\n",
      "Epoch [4/40] : train loss 0.766803, train metric 0.766803, val loss 0.650840, val metric 0.650840\n",
      "Epoch [6/40] : train loss 0.710113, train metric 0.710113, val loss 0.629979, val metric 0.629979\n",
      "Epoch [8/40] : train loss 0.705764, train metric 0.705764, val loss 0.614175, val metric 0.614175\n",
      "Epoch [10/40] : train loss 0.659801, train metric 0.659801, val loss 0.604046, val metric 0.604046\n",
      "Epoch [12/40] : train loss 0.623016, train metric 0.623016, val loss 0.599857, val metric 0.599857\n",
      "Epoch [14/40] : train loss 0.646827, train metric 0.646827, val loss 0.595363, val metric 0.595363\n",
      "Epoch [16/40] : train loss 0.585484, train metric 0.585484, val loss 0.590625, val metric 0.590625\n",
      "Epoch [18/40] : train loss 0.611349, train metric 0.611349, val loss 0.595668, val metric 0.595668\n",
      "Epoch [20/40] : train loss 0.553972, train metric 0.553972, val loss 0.593703, val metric 0.593703\n",
      "Epoch    19: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [22/40] : train loss 0.554813, train metric 0.554813, val loss 0.606054, val metric 0.606054\n",
      "Epoch [24/40] : train loss 0.538404, train metric 0.538404, val loss 0.608257, val metric 0.608257\n",
      "Epoch    23: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [26/40] : train loss 0.459135, train metric 0.459135, val loss 0.594226, val metric 0.594226\n",
      "Early stopping\n",
      "Epoch [2/40] : train loss 0.763462, train metric 0.763462, val loss 0.691725, val metric 0.691725\n",
      "Epoch [4/40] : train loss 0.730365, train metric 0.730365, val loss 0.665384, val metric 0.665384\n",
      "Epoch [6/40] : train loss 0.648618, train metric 0.648618, val loss 0.647860, val metric 0.647860\n",
      "Epoch [8/40] : train loss 0.604820, train metric 0.604820, val loss 0.636925, val metric 0.636925\n",
      "Epoch [10/40] : train loss 0.603690, train metric 0.603690, val loss 0.633962, val metric 0.633962\n",
      "Epoch [12/40] : train loss 0.585040, train metric 0.585040, val loss 0.626160, val metric 0.626160\n",
      "Epoch [14/40] : train loss 0.588807, train metric 0.588807, val loss 0.624341, val metric 0.624341\n",
      "Epoch [16/40] : train loss 0.577530, train metric 0.577530, val loss 0.611512, val metric 0.611512\n",
      "Epoch [18/40] : train loss 0.605250, train metric 0.605250, val loss 0.612305, val metric 0.612305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/40] : train loss 0.498397, train metric 0.498397, val loss 0.614259, val metric 0.614259\n",
      "Epoch [22/40] : train loss 0.477484, train metric 0.477484, val loss 0.604126, val metric 0.604126\n",
      "Epoch [24/40] : train loss 0.498833, train metric 0.498833, val loss 0.618977, val metric 0.618977\n",
      "Epoch [26/40] : train loss 0.467704, train metric 0.467704, val loss 0.616852, val metric 0.616852\n",
      "Epoch    25: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [28/40] : train loss 0.411967, train metric 0.411967, val loss 0.613680, val metric 0.613680\n",
      "Epoch [30/40] : train loss 0.397340, train metric 0.397340, val loss 0.618367, val metric 0.618367\n",
      "Epoch    29: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [32/40] : train loss 0.331900, train metric 0.331900, val loss 0.618906, val metric 0.618906\n",
      "Early stopping\n",
      "Epoch [2/40] : train loss 0.732483, train metric 0.732483, val loss 0.709810, val metric 0.709810\n",
      "Epoch [4/40] : train loss 0.670014, train metric 0.670014, val loss 0.682253, val metric 0.682253\n",
      "Epoch [6/40] : train loss 0.600056, train metric 0.600056, val loss 0.661819, val metric 0.661819\n",
      "Epoch [8/40] : train loss 0.589561, train metric 0.589561, val loss 0.653431, val metric 0.653431\n",
      "Epoch [10/40] : train loss 0.598341, train metric 0.598341, val loss 0.642880, val metric 0.642880\n",
      "Epoch [12/40] : train loss 0.601181, train metric 0.601181, val loss 0.630715, val metric 0.630715\n",
      "Epoch [14/40] : train loss 0.526252, train metric 0.526252, val loss 0.620690, val metric 0.620690\n",
      "Epoch [16/40] : train loss 0.552445, train metric 0.552445, val loss 0.624638, val metric 0.624638\n",
      "Epoch [18/40] : train loss 0.551060, train metric 0.551060, val loss 0.614839, val metric 0.614839\n",
      "Epoch [20/40] : train loss 0.519367, train metric 0.519367, val loss 0.620126, val metric 0.620126\n",
      "Epoch [22/40] : train loss 0.530545, train metric 0.530545, val loss 0.617575, val metric 0.617575\n",
      "Epoch    21: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [24/40] : train loss 0.460573, train metric 0.460573, val loss 0.618623, val metric 0.618623\n",
      "Epoch [26/40] : train loss 0.485949, train metric 0.485949, val loss 0.622999, val metric 0.622999\n",
      "Epoch    25: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [28/40] : train loss 0.457105, train metric 0.457105, val loss 0.627688, val metric 0.627688\n",
      "Early stopping\n",
      "Epoch [2/40] : train loss 0.689738, train metric 0.689738, val loss 0.694214, val metric 0.694214\n",
      "Epoch [4/40] : train loss 0.683488, train metric 0.683488, val loss 0.658239, val metric 0.658239\n",
      "Epoch [6/40] : train loss 0.643625, train metric 0.643625, val loss 0.634048, val metric 0.634048\n",
      "Epoch [8/40] : train loss 0.647295, train metric 0.647295, val loss 0.621528, val metric 0.621528\n",
      "Epoch [10/40] : train loss 0.567853, train metric 0.567853, val loss 0.607056, val metric 0.607056\n",
      "Epoch [12/40] : train loss 0.579293, train metric 0.579293, val loss 0.596476, val metric 0.596476\n",
      "Epoch [14/40] : train loss 0.545094, train metric 0.545094, val loss 0.594002, val metric 0.594002\n",
      "Epoch [16/40] : train loss 0.539230, train metric 0.539230, val loss 0.583537, val metric 0.583537\n",
      "Epoch [18/40] : train loss 0.542560, train metric 0.542560, val loss 0.588557, val metric 0.588557\n",
      "Epoch    18: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch [20/40] : train loss 0.491253, train metric 0.491253, val loss 0.567083, val metric 0.567083\n",
      "Epoch [22/40] : train loss 0.493831, train metric 0.493831, val loss 0.567885, val metric 0.567885\n",
      "Epoch [24/40] : train loss 0.484664, train metric 0.484664, val loss 0.570500, val metric 0.570500\n",
      "Epoch    23: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [26/40] : train loss 0.431189, train metric 0.431189, val loss 0.571961, val metric 0.571961\n",
      "Epoch [28/40] : train loss 0.467753, train metric 0.467753, val loss 0.578161, val metric 0.578161\n",
      "Epoch    27: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch [30/40] : train loss 0.417210, train metric 0.417210, val loss 0.572503, val metric 0.572503\n",
      "Early stopping\n",
      "Training loss :  0.36561915601127204\n",
      "Validation loss :  0.4515563364565321\n",
      "Test loss :  0.4685312699535\n",
      "Train accuracy 0.836325, precision 0.693408, recall 0.709805, f1 0.701178 \n",
      "Valid accuracy 0.792620, precision 0.617992, recall 0.615943, f1 0.616494 \n",
      "Test  accuracy 0.785475, precision 0.610173, recall 0.600490, f1 0.604885 \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "nfold = 7\n",
    "skf = StratifiedKFold(n_splits = nfold, shuffle=True, random_state = SEED)\n",
    "\n",
    "train_loss, val_loss, test_loss = [], [],[]\n",
    "train_accu, val_accu, test_accu = [], [], []\n",
    "train_prec, val_prec, test_prec = [], [], []\n",
    "train_recall, val_recall, test_recall = [], [], []\n",
    "train_f1, val_f1, test_f1 = [], [], []\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    train, val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    train_targets, val_targets = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    params_net = {'input_size': train.shape[1],\n",
    "                  'hidden_size':[512, 256],\n",
    "                  'output_size':1,\n",
    "                  'dropout':[0, 0.1, 0.1]}\n",
    "    params_fit = {'X_train':train, 'y_train':train_targets,\n",
    "                 'X_val':val, 'y_val': val_targets,\n",
    "                 'epoch': 40,\n",
    "                  'batch_size':128,\n",
    "                  'smoothing': 0,\n",
    "                  'pos_weight': 1.75,\n",
    "                 'lr': 1e-3,\n",
    "                 'weight_decay':2e-5}\n",
    "    net = DenseNet(**params_net)\n",
    "    model = Model(net)\n",
    "    model.fit(**params_fit)\n",
    "    \n",
    "    train_pred_proba = model.predict_proba(train)\n",
    "    val_pred_proba = model.predict_proba(val)\n",
    "    test_pred_proba = model.predict_proba(X_test)\n",
    "    # neg log loss\n",
    "    train_loss.append(log_loss(train_targets, train_pred_proba))\n",
    "    val_loss.append(log_loss(val_targets, val_pred_proba))\n",
    "    test_loss.append(log_loss(y_test, test_pred_proba))\n",
    "    \n",
    "    train_pred = model.predict(train)\n",
    "    val_pred = model.predict(val)\n",
    "    test_pred = model.predict(X_test)\n",
    "    # accuracy\n",
    "    train_accu.append(accuracy_score(train_targets, train_pred))\n",
    "    val_accu.append(accuracy_score(val_targets, val_pred))\n",
    "    test_accu.append(accuracy_score(y_test, test_pred))\n",
    "    # precision\n",
    "    train_prec.append(precision_score(train_targets, train_pred))\n",
    "    val_prec.append(precision_score(val_targets, val_pred))\n",
    "    test_prec.append(precision_score(y_test, test_pred))\n",
    "    # recall\n",
    "    train_recall.append(recall_score(train_targets, train_pred))\n",
    "    val_recall.append(recall_score(val_targets, val_pred))\n",
    "    test_recall.append(recall_score(y_test, test_pred))\n",
    "    # f1 score\n",
    "    train_f1.append(f1_score(train_targets, train_pred))\n",
    "    val_f1.append(f1_score(val_targets, val_pred))\n",
    "    test_f1.append(f1_score(y_test, test_pred))\n",
    "    \n",
    "\n",
    "print('Training loss : ', np.average(np.array(train_loss)))\n",
    "print('Validation loss : ', np.average(np.array(val_loss)))\n",
    "print('Test loss : ', np.average(np.array(test_loss)))\n",
    "\n",
    "train_accu_avg = np.average(np.array(train_accu))\n",
    "train_prec_avg = np.average(np.array(train_prec))\n",
    "train_recall_avg = np.average(np.array(train_recall))\n",
    "train_f1_avg = np.average(np.array(train_f1))\n",
    "print('Train accuracy {:5f}, precision {:5f}, recall {:5f}, f1 {:5f} '.format(train_accu_avg, train_prec_avg, train_recall_avg, train_f1_avg))\n",
    "\n",
    "val_accu_avg = np.average(np.array(val_accu))\n",
    "val_prec_avg = np.average(np.array(val_prec))\n",
    "val_recall_avg = np.average(np.array(val_recall))\n",
    "val_f1_avg = np.average(np.array(val_f1))\n",
    "print('Valid accuracy {:5f}, precision {:5f}, recall {:5f}, f1 {:5f} '.format(val_accu_avg, val_prec_avg, val_recall_avg, val_f1_avg))\n",
    "\n",
    "test_accu_avg = np.average(np.array(test_accu))\n",
    "test_prec_avg = np.average(np.array(test_prec))\n",
    "test_recall_avg = np.average(np.array(test_recall))\n",
    "test_f1_avg = np.average(np.array(test_f1))\n",
    "print('Test  accuracy {:5f}, precision {:5f}, recall {:5f}, f1 {:5f} '.format(test_accu_avg, test_prec_avg, test_recall_avg, test_f1_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(512, 256)   \n",
    "Training loss :  0.34193550539367834   \n",
    "Validation loss :  0.43192105301030237  \n",
    "Test loss :  0.44936967781324955   \n",
    "Train accuracy 0.847603, precision 0.809408, recall 0.571245, f1 0.669641   \n",
    "Valid accuracy 0.805032, precision 0.706707, recall 0.478604, f1 0.570592   \n",
    "Test  accuracy 0.799751, precision 0.710162, recall 0.453606, f1 0.553425  \n",
    "\n",
    "(512, 128)\n",
    "Training loss :  0.35124593625785494  \n",
    "Validation loss :  0.4295628168406127   \n",
    "Test loss :  0.4481831115372716  \n",
    "Train accuracy 0.843298, precision 0.804207, recall 0.556211, f1 0.657367   \n",
    "Valid accuracy 0.805367, precision 0.712201, recall 0.470858, f1 0.566863   \n",
    "Test  accuracy 0.798026, precision 0.707143, recall 0.448004, f1 0.548119 \n",
    "\n",
    "(256, 128)\n",
    "Training loss :  0.3629471524333735   \n",
    "Validation loss :  0.4292373239584619   \n",
    "Test loss :  0.44721303387134104   \n",
    "Train accuracy 0.836953, precision 0.791978, recall 0.539315, f1 0.641228   \n",
    "Valid accuracy 0.803522, precision 0.712225, recall 0.460947, f1 0.559229    \n",
    "Test  accuracy 0.796733, precision 0.706601, recall 0.441001, f1 0.542603 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
